{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutual Fund Investment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python (Flask) App, majorly for Backend APIs for Individual Mutual Fund Investment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "Over the years, investors have tried and tested various methodologies to keep a track of all investements. The various problems faced for the same are -\n",
    "\n",
    "1. Multi-vendor - The Mutual Funds are invested via multiple vendors, like Groww, Paytm Money, etc., hence no unified interface to track all investments.\n",
    "2. The historic data is not accurately predicted - Over time the historic data loses importance and is overriden to be fitted only in Time Series Graph.\n",
    "3. Periodic Tracking of data - Everyday net change in the invested amount.\n",
    "4. Personalized Prediction - Currently all Mutual Fund Predictions are not personalized, only based on overall NAV changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data collection, Storage and Analysis Blueprint\n",
    "\n",
    "Data from differen apps will be collected in the following way -\n",
    "\n",
    "1. Per day data of return is manually entered in Google Sheet.\n",
    "2. The data from the Google Sheet is fetched in Python, and stored in a MySQL DB.\n",
    "3. Data fetching happens everyday, at 11:00 a.m. (APScheduler)\n",
    "4. Success or failure mails for everyday update is triggered based on the storage of data in the respective database.\n",
    "5. APIs expose the various data, grouped by various factors to be used in the UI.\n",
    "6. Once the stored data crosses a significant volume, this data is splitted into train and test data for future analysis.\n",
    "7. The predicted data is again exposed over APIs, grouped by various factors.\n",
    "\n",
    "Data collection update as on (Dec 23, 2020) -\n",
    "1. Maintaining a seperate spreadsheet to update the NAV for each Fund.\n",
    "2. Utilizing Google Finance capabiliites to auto-update the fund for each NAV\n",
    "3. Data from the spreadsheet is loaded into the dataframe, everytime ALexa/App is initialized, or after every 15 mins.\n",
    "4. If the current date is equal to last date in the sheet, the corresponding cells are updated. If not, new rows are added.\n",
    "5. Continued from Point 5 as above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to Google Sheet\n",
    "\n",
    "Our primary data source is google sheet, where the daily changes for all the mutual funds, are recorded.\n",
    "\n",
    "To connect the Google Sheet, we perform the following -\n",
    "\n",
    "1. Go to https://console.cloud.google.com/ and create a new Project.\n",
    "2. In the created project, enable Google Drive API\n",
    "3. Create credentials to access the Google Drive API.\n",
    "4. Enable the Google Sheets API\n",
    "5. Share the Google Sheet with the dev ID generated in the credential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All imports at one place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import pandas as pd\n",
    "from datetime import datetime,timedelta,date\n",
    "import smtplib\n",
    "from email.message import EmailMessage\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the scope of the OAuth Authentication\n",
    "scope = [\"https://spreadsheets.google.com/feeds\",'https://www.googleapis.com/auth/spreadsheets',\"https://www.googleapis.com/auth/drive.file\",\"https://www.googleapis.com/auth/drive\"]\n",
    "         \n",
    "#Getting the credentials\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name(\"./flask_app/src/secret_config/google_credentials.json\", scope)\n",
    "#Connecting to the Google Spreadsheet Client\n",
    "client = gspread.authorize(creds)\n",
    "\n",
    "#Getting the spreadsheet\n",
    "sheet = client.open(\"Daily_MF_Returns\").sheet1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting all the data from the sheet\n",
    "\n",
    "Explore the sheet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_data = sheet.get_all_records()\n",
    "\n",
    "#Creating the dataframe\n",
    "data = pd.DataFrame(list_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260, 6)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rows and Column Count for the data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Policy Name', 'App', 'Investment', 'Return', 'Net Change'], dtype='object')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Column Names of the data\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 260 entries, 0 to 259\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Date         260 non-null    object \n",
      " 1   Policy Name  260 non-null    object \n",
      " 2   App          260 non-null    object \n",
      " 3   Investment   260 non-null    int64  \n",
      " 4   Return       260 non-null    float64\n",
      " 5   Net Change   260 non-null    float64\n",
      "dtypes: float64(2), int64(1), object(3)\n",
      "memory usage: 12.3+ KB\n"
     ]
    }
   ],
   "source": [
    "#explore the data\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['12/24/2020', 'Nippon India Liquid Fund', 'Paytm Money', 800,\n",
       "        807.76, 7.76],\n",
       "       ['12/24/2020', 'ICICI Prudential Regular Gold', 'Groww', 1000,\n",
       "        997.88, -2.12],\n",
       "       ['12/24/2020', 'Axis Midcap Direct', 'Groww', 1000, 1032.27,\n",
       "        32.27],\n",
       "       ['12/24/2020', 'Axis Bluechip', 'Groww', 1000, 1033.58, 33.58],\n",
       "       ['12/24/2020', 'SBI Magnum', 'Groww', 500, 503.17, 3.17]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(5).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing Empty Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace([''],'Unknown',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Formatted Date column to the dataframe\n",
    "\n",
    "The new column contains date in format DD-MMM-YYYY to avoid ambiguity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coverting all the values in proper Datetime format\n",
    "\n",
    "def validate(date_text):\n",
    "    try:\n",
    "        return datetime.strptime(date_text, '%m/%d/%Y').strftime(\"%d-%b-%Y\")\n",
    "    except ValueError:\n",
    "        print(date_text)\n",
    "        return date_text\n",
    "    \n",
    "data['date_formatted'] = data['Date'].apply(validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data from NAV Sheet (Auto updated by Google Finance Formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the scope of the OAuth Authentication\n",
    "scope = [\"https://spreadsheets.google.com/feeds\",'https://www.googleapis.com/auth/spreadsheets',\"https://www.googleapis.com/auth/drive.file\",\"https://www.googleapis.com/auth/drive\"]\n",
    "         \n",
    "#Getting the credentials\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name(\"./flask_app/src/secret_config/google_credentials.json\", scope)\n",
    "#Connecting to the Google Spreadsheet Client\n",
    "client = gspread.authorize(creds)\n",
    "\n",
    "#Getting the spreadsheet\n",
    "nav_sheet = client.open(\"Daily_NAV_Change\").sheet1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the data sheet\n",
    "\n",
    "1. Convertig the datasheet into pandas data-frame\n",
    "2. Explore the datasheet (should have rows equal to the number of distinct funds)\n",
    "3. The order of the mutual-funds should be same as the other sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Policy Name          App                         MF Code  \\\n",
      "0              IDFC Low Duration  Paytm Money    MUTF_IN:IDFC_LOW_DURA_4QUGMB   \n",
      "1                        BOI AXA  Paytm Money     MUTF_IN:BOI_AXA_MID_1I3GT7A   \n",
      "2                 SBI Short Term  Paytm Money    MUTF_IN:SBI_SHOR_TERM_9CH6IA   \n",
      "3      Edelweiss Banking and PSU  Paytm Money    MUTF_IN:EDEL_BNKG_PSU_8BZNFF   \n",
      "4               HDFC Gold Direct  Paytm Money     MUTF_IN:HDFC_GOLD_GR_NYUXR1   \n",
      "5       Nippon India Liquid Fund  Paytm Money  MUTF_IN:NIPP_INDI_LIQU_1YFEPRJ   \n",
      "6  ICICI Prudential Regular Gold        Groww    MUTF_IN:ICIC_PRU_REG_1U0TLER   \n",
      "7             Axis Midcap Direct        Groww    MUTF_IN:AXIS_MIDC_DIR_C59UK9   \n",
      "8                  Axis Bluechip        Groww    MUTF_IN:AXIS_SMAL_CAP_OE6ZGA   \n",
      "9                     SBI Magnum        Groww   MUTF_IN:SBI_MAGN_CONS_1HGOM1I   \n",
      "\n",
      "   Latest NAV   Units  Current Value  \n",
      "0       30.38  54.978     1670.23164  \n",
      "1       15.77  13.422      211.66494  \n",
      "2       26.02  58.016     1509.57632  \n",
      "3       19.38  51.658     1001.13204  \n",
      "4       15.96  59.364      947.44944  \n",
      "5     4955.61   0.163      807.76443  \n",
      "6       16.86  59.186      997.87596  \n",
      "7       52.71  19.584     1032.27264  \n",
      "8       40.89  25.277     1033.57653  \n",
      "9       51.00   9.866      503.16600  \n"
     ]
    }
   ],
   "source": [
    "nav_list = nav_sheet.get_all_records()\n",
    "\n",
    "#Creating the dataframe\n",
    "nav_frame = pd.DataFrame(nav_list)\n",
    "\n",
    "#Getting the shape of the frame\n",
    "nav_frame.shape\n",
    "\n",
    "print(nav_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data clean-up\n",
    "\n",
    "1. Remove the rows containing MF Code, Latest NAV and Units\n",
    "2. Create the list of current values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1670.23, 211.66, 1509.58, 1001.13, 947.45, 807.76, 997.88, 1032.27, 1033.58, 503.17]\n"
     ]
    }
   ],
   "source": [
    "nav_frame = nav_frame.drop(['MF Code', 'Latest NAV', 'Units'], axis=1)\n",
    "\n",
    "#Round the current values\n",
    "nav_frame['Current Value'] = nav_frame['Current Value'].apply(lambda x: round(x,2))\n",
    "\n",
    "current_values_list = list(map(lambda x: x[2], nav_frame.values))\n",
    "\n",
    "print(current_values_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify whether the latest date from the original sheet is the current date\n",
    "\n",
    "1. Get the rows only with the latest dates\n",
    "2. Fetch the latest date and check with the current date\n",
    "3. If latest date and current date matches, calculate the cell numbers and update.\n",
    "4. If not, insert new rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Row - 252 and Column - 5\n",
      "Updated Row - 253 and Column - 5\n",
      "Updated Row - 254 and Column - 5\n",
      "Updated Row - 255 and Column - 5\n",
      "Updated Row - 256 and Column - 5\n",
      "Updated Row - 257 and Column - 5\n",
      "Updated Row - 258 and Column - 5\n",
      "Updated Row - 259 and Column - 5\n",
      "Updated Row - 260 and Column - 5\n",
      "Updated Row - 261 and Column - 5\n"
     ]
    }
   ],
   "source": [
    "is_update = False\n",
    "\n",
    "current_length = len(list_data)\n",
    "\n",
    "#Getting the last date\n",
    "last_date = data.values[current_length-1][0]\n",
    "\n",
    "#Getting all the rows corresponding to the last date\n",
    "data_filtered = data.loc[data['Date'] == last_date]\n",
    "\n",
    "#Drop the date_formatted column\n",
    "data_filtered = data_filtered.drop(['date_formatted'], axis=1)\n",
    "\n",
    "#Get the current date in the same format\n",
    "current_date = date.today().strftime(\"%m/%d/%Y\")\n",
    "\n",
    "if(current_date == last_date):\n",
    "    is_update = True\n",
    "\n",
    "#Get the starting column and row number\n",
    "column_number = 5\n",
    "start_row_number = current_length - len(current_values_list) + 2\n",
    "end_row_number = current_length + 1\n",
    "\n",
    "# If Update\n",
    "if(is_update):\n",
    "    for value in current_values_list:\n",
    "        sheet.update_cell(start_row_number,column_number, value)\n",
    "        print(\"Updated Row - {} and Column - {}\".format(start_row_number, column_number))\n",
    "        \n",
    "        start_row_number += 1\n",
    "\n",
    "#If Insert\n",
    "else:\n",
    "    current_data_list = data_filtered.values\n",
    "    \n",
    "    for index in range(0,len(current_values_list)):\n",
    "        current_data_list[index][0] = current_date\n",
    "        current_data_list[index][4] = current_values_list[index]        \n",
    "        current_data_list[index][5] = round(current_data_list[index][4] - current_data_list[index][3],2)\n",
    "    \n",
    "    for each_data in current_data_list:\n",
    "        end_row_number += 1\n",
    "        each_data_list = each_data.tolist()\n",
    "        sheet.insert_row(each_data_list, end_row_number, 'RAW')\n",
    "        print(\"Inserted Row - {}\".format(end_row_number))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update the Excel for next week (repetitive)\n",
    "\n",
    "### Get the last date, and all the records for last date\n",
    "We'll update the data for next week (Tuesday - Saturday), every previous Saturday\n",
    "To do this the following has to be calculated -\n",
    "\n",
    "1. Index of the current pointer in the excel\n",
    "2. The last date\n",
    "3. All the records for the last date (fetch Date, Policy Name, App and Investment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['11/28/2020', 'IDFC Low Duration', 'Paytm Money', 1600], ['11/28/2020', 'BOI AXA', 'Paytm Money', 200], ['11/28/2020', 'SBI Short Term', 'Paytm Money', 1000], ['11/28/2020', 'Edelweiss Banking and PSU', 'Paytm Money', 500], ['11/28/2020', 'HDFC Gold Direct', 'Paytm Money', 500], ['11/28/2020', 'Nippon India Liquid Fund', 'Paytm Money', 800], ['11/28/2020', 'ICICI Prudential Regular Gold', 'Groww', 500], ['11/28/2020', 'Axis Midcap Direct', 'Groww', 500], ['11/28/2020', 'Axis Bluechip', 'Groww', 500], ['11/28/2020', 'SBI Magnum', 'Groww', 500]]\n"
     ]
    }
   ],
   "source": [
    "current_pointer = len(list_data)\n",
    "\n",
    "#Getting the last date\n",
    "last_date = data.values[current_pointer-1][0]\n",
    "\n",
    "#Getting all the rows corresponding to the last date\n",
    "data_filtered = data.loc[data['Date'] == last_date]\n",
    "\n",
    "data_filtered = data_filtered.drop(['Return','Net Change', 'date_formatted'],axis=1)\n",
    "\n",
    "# List of dictionaries\n",
    "list_to_insert = data_filtered.values.tolist()\n",
    "\n",
    "print(list_to_insert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the final list of data to be inserted\n",
    "\n",
    "1. Start from 2 days from the date\n",
    "2. Create for 5 days\n",
    "3. Total # rows = Current # rows * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_insert_list = []\n",
    "\n",
    "for i in range(0,5):\n",
    "    for each_row in list_to_insert:        \n",
    "        final_insert_list.append(each_row)\n",
    "\n",
    "# Yield successive n-sized \n",
    "# chunks from l. \n",
    "def divide_chunks(l, n):       \n",
    "    # looping till length l \n",
    "    for i in range(0, len(l), n):  \n",
    "        yield l[i:i + n]\n",
    "        \n",
    "days_chunk = list(divide_chunks(final_insert_list, len(list_to_insert)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Records and Send Mail\n",
    "\n",
    "1. Update the next weeks data in the sheet\n",
    "2. Send success and failure mails accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Row - 82\n",
      "Updated Row - 83\n",
      "Updated Row - 84\n",
      "Updated Row - 85\n",
      "Updated Row - 86\n",
      "Updated Row - 87\n",
      "Updated Row - 88\n",
      "Updated Row - 89\n",
      "Updated Row - 90\n",
      "Updated Row - 91\n",
      "Updated Row - 92\n",
      "Updated Row - 93\n",
      "Updated Row - 94\n",
      "Updated Row - 95\n",
      "Updated Row - 96\n",
      "Updated Row - 97\n",
      "Updated Row - 98\n",
      "Updated Row - 99\n",
      "Updated Row - 100\n",
      "Updated Row - 101\n",
      "Updated Row - 102\n",
      "Updated Row - 103\n",
      "Updated Row - 104\n",
      "Updated Row - 105\n",
      "Updated Row - 106\n",
      "Updated Row - 107\n",
      "Updated Row - 108\n",
      "Updated Row - 109\n",
      "Updated Row - 110\n",
      "Updated Row - 111\n",
      "Updated Row - 112\n",
      "Updated Row - 113\n",
      "Updated Row - 114\n",
      "Updated Row - 115\n",
      "Updated Row - 116\n",
      "Updated Row - 117\n",
      "Updated Row - 118\n",
      "Updated Row - 119\n",
      "Updated Row - 120\n",
      "Updated Row - 121\n",
      "Updated Row - 122\n",
      "Updated Row - 123\n",
      "Updated Row - 124\n",
      "Updated Row - 125\n",
      "Updated Row - 126\n",
      "Updated Row - 127\n",
      "Updated Row - 128\n",
      "Updated Row - 129\n",
      "Updated Row - 130\n",
      "Updated Row - 131\n",
      "Email sent successfully\n"
     ]
    }
   ],
   "source": [
    "def email_alert(subject, body, to):\n",
    "    msg=EmailMessage()\n",
    "    msg.set_content(body)\n",
    "    msg['subject']=subject\n",
    "    msg['to'] = to\n",
    "    \n",
    "    gmail_credentials_file = open(\"./flask_app/src/secret_config/gmail_credentials.json\")\n",
    "    gmail_credentials = json.load(gmail_credentials_file)\n",
    "    \n",
    "    sender = gmail_credentials['email']\n",
    "    password = gmail_credentials['password']    \n",
    "    \n",
    "    msg['from'] = sender\n",
    "    \n",
    "    server = smtplib.SMTP(\"smtp.gmail.com\", 587)\n",
    "    server.starttls()\n",
    "    server.login(sender,password)\n",
    "    \n",
    "    server.send_message(msg)\n",
    "    server.quit()\n",
    "    print(\"Email sent successfully\");\n",
    "\n",
    "success_insert = True\n",
    "total_rows = data.shape[0] + 2 # 1st Row is heading\n",
    "\n",
    "days_delta = 3\n",
    "\n",
    "for each_chunk in days_chunk:\n",
    "    if(success_insert):\n",
    "        date_to_add = (datetime.strptime(last_date, '%m/%d/%Y') + timedelta(days=days_delta)).strftime('%m/%d/%Y')\n",
    "        for value in each_chunk:\n",
    "            value[0] = date_to_add\n",
    "            try:\n",
    "                sheet.insert_row(value, total_rows, 'RAW')\n",
    "                print(\"Updated Row - \" + str(total_rows))\n",
    "                total_rows += 1                \n",
    "            except:\n",
    "                print(\"Error in Row - \" + str(total_rows))\n",
    "                success_insert = False\n",
    "                break\n",
    "        days_delta +=1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "start_date = (datetime.strptime(last_date, '%m/%d/%Y') + timedelta(days=3)).strftime('%d-/%b-%Y')\n",
    "\n",
    "if(success_insert):\n",
    "    body = '''\n",
    "    Hi Apratim,\n",
    "    \n",
    "    The weekly scheduled insert of data is successful. Data is inserted for the next 5 days, starting from Tuesday - {var}.\n",
    "    Please update the returns accordingly.\n",
    "    \n",
    "    Best Regards,\n",
    "    Dev Team\n",
    "    Mutual Fund Analysis App'''.format(var=start_date)\n",
    "else:\n",
    "    body = '''\n",
    "    Hi Apratim,\n",
    "    \n",
    "    There was some issue in updating your data. Rest assured our team is working on it.\n",
    "    Meanwhile please update the data and returns manually, starting from - {var}.\n",
    "    Sorry for the incovenience caused.\n",
    "    \n",
    "    Best Regards,\n",
    "    Dev Team\n",
    "    Mutual Fund Analysis App'''.format(var=start_date)\n",
    "    \n",
    "subject = \"Mutual Funds - Weekly Insertion of Base Data\"\n",
    "to = \"apratimnath7@gmail.com\";\n",
    "\n",
    "email_alert(subject, body, to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculations (Transferred via API)\n",
    "\n",
    "API 1 - Get the daily change based on the following parameters -\n",
    "1. Overall\n",
    "2. App Based\n",
    "3. Fund Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-65-30f27d17b758>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  last_date_rows['Investment'] = pd.to_numeric(last_date_rows['Investment'])\n",
      "<ipython-input-65-30f27d17b758>:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  last_date_rows['Return'] = pd.to_numeric(last_date_rows['Return'])\n",
      "<ipython-input-65-30f27d17b758>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  last_date_rows['Net Change'] = pd.to_numeric(last_date_rows['Net Change'])\n"
     ]
    }
   ],
   "source": [
    "#Subset of data containing returns\n",
    "valid_data_with_returns = data.loc[data['Return'] != 'Unknown']\n",
    "\n",
    "length_of_valid_returns = valid_data_with_returns.shape[0]\n",
    "\n",
    "#Getting the last date\n",
    "last_date = valid_data_with_returns.values[length_of_valid_returns-1][0]\n",
    "\n",
    "#Get the last date and the date before that data\n",
    "last_date_rows = valid_data_with_returns.loc[valid_data_with_returns['Date'] == last_date]\n",
    "previous_date_rows = valid_data_with_returns.loc[valid_data_with_returns['Date'] != last_date].tail(last_date_rows.shape[0])\n",
    "\n",
    "# last_date_rows_list = last_date_rows.values.tolist()\n",
    "# previous_date_rows_list = previous_date_rows.values.tolist()\n",
    "\n",
    "#Convert to numeric\n",
    "last_date_rows['Investment'] = pd.to_numeric(last_date_rows['Investment'])\n",
    "last_date_rows['Return'] = pd.to_numeric(last_date_rows['Return'])\n",
    "last_date_rows['Net Change'] = pd.to_numeric(last_date_rows['Net Change'])\n",
    "\n",
    "previous_date_rows['Investment'] = pd.to_numeric(previous_date_rows['Investment'])\n",
    "previous_date_rows['Return'] = pd.to_numeric(previous_date_rows['Return'])\n",
    "previous_date_rows['Net Change'] = pd.to_numeric(previous_date_rows['Net Change'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### App Wise Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'app_name': 'Groww', 'sum_difference': 8.0, 'mean_difference': 2.0, 'standard_deviation_difference': 4.7}, {'app_name': 'Paytm Money', 'sum_difference': 0.49, 'mean_difference': 0.08, 'standard_deviation_difference': -0.39}]\n"
     ]
    }
   ],
   "source": [
    "#App-wise calculation\n",
    "grouped_last = last_date_rows.groupby('App',as_index=False).agg({'Net Change':[np.sum, np.mean, np.std]})\n",
    "grouped_previous = previous_date_rows.groupby('App',as_index=False).agg({'Net Change':[np.sum, np.mean, np.std]})\n",
    "\n",
    "#Rename previos frame colums\n",
    "grouped_previous.columns = ['app','prev_sum','prev_mean','prev_std']\n",
    "\n",
    "\n",
    "#Create single comparision frame\n",
    "compare_frame = grouped_last\n",
    "compare_frame.columns = ['app','current_sum','current_mean','current_std']\n",
    "\n",
    "compare_frame['prev_sum'] = grouped_previous['prev_sum']\n",
    "compare_frame['prev_mean'] = grouped_previous['prev_mean']\n",
    "compare_frame['prev_std'] = grouped_previous['prev_std']\n",
    "\n",
    "compare_frame['sum_diff'] = np.where(compare_frame['current_sum'] == compare_frame['prev_sum'], 0 , compare_frame['current_sum'] - compare_frame['prev_sum'])\n",
    "compare_frame['mean_diff'] = np.where(compare_frame['current_mean'] == compare_frame['prev_mean'], 0 , compare_frame['current_mean'] - compare_frame['prev_mean'])\n",
    "compare_frame['std_diff'] = np.where(compare_frame['current_std'] == compare_frame['prev_std'], 0 , compare_frame['current_std'] - compare_frame['prev_std'])\n",
    "\n",
    "compare_frame = compare_frame.drop(['current_sum','current_mean', 'current_std', 'prev_sum','prev_mean', 'prev_std'],axis=1)\n",
    "\n",
    "app_diff_list = compare_frame.values.tolist()\n",
    "\n",
    "app_dict_list = []\n",
    "for each_app in app_diff_list:\n",
    "    current_dict = {}\n",
    "    current_dict['app_name'] = each_app[0]\n",
    "    current_dict['sum_difference'] = round(each_app[1],2)\n",
    "    current_dict['mean_difference'] = round(each_app[2],2)\n",
    "    current_dict['standard_deviation_difference'] = round(each_app[3],2)\n",
    "    \n",
    "    app_dict_list.append(current_dict)\n",
    "\n",
    "print(app_dict_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fund Based Calculation\n",
    "\n",
    "Since the values are independent, ideally group by has no effect.\n",
    "\n",
    "However, we keep on using the costlier grouping to keep things inline with the previous implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'policy_name': 'Axis Bluechip', 'sum_difference': -1.0}, {'policy_name': 'Axis Midcap Direct', 'sum_difference': 10.0}, {'policy_name': 'BOI AXA', 'sum_difference': 2.82}, {'policy_name': 'Edelweiss Banking and PSU', 'sum_difference': 0.1}, {'policy_name': 'HDFC Gold Direct', 'sum_difference': -2.11}, {'policy_name': 'ICICI Prudential Regular Gold', 'sum_difference': -1.0}, {'policy_name': 'IDFC Low Duration', 'sum_difference': 0.09}, {'policy_name': 'Nippon India Liquid Fund', 'sum_difference': 0.06}, {'policy_name': 'SBI Magnum', 'sum_difference': 0.0}, {'policy_name': 'SBI Short Term', 'sum_difference': -0.47}]\n"
     ]
    }
   ],
   "source": [
    "#Fund-wise calculation\n",
    "grouped_last = last_date_rows.groupby('Policy Name',as_index=False).agg({'Net Change':[np.sum]})\n",
    "grouped_previous = previous_date_rows.groupby('Policy Name',as_index=False).agg({'Net Change':[np.sum]})\n",
    "\n",
    "#Rename previos frame colums\n",
    "grouped_previous.columns = ['policy_name','prev_sum']\n",
    "\n",
    "\n",
    "#Create single comparision frame\n",
    "compare_frame = grouped_last\n",
    "compare_frame.columns = ['policy_name','current_sum']\n",
    "\n",
    "compare_frame['prev_sum'] = grouped_previous['prev_sum']\n",
    "\n",
    "compare_frame['sum_diff'] = np.where(compare_frame['current_sum'] == compare_frame['prev_sum'], 0 , compare_frame['current_sum'] - compare_frame['prev_sum'])\n",
    "\n",
    "compare_frame = compare_frame.drop(['current_sum', 'prev_sum'],axis=1)\n",
    "\n",
    "policy_diff_list = compare_frame.values.tolist()\n",
    "\n",
    "policy_dict_list = []\n",
    "for each_policy in policy_diff_list:\n",
    "    current_dict = {}\n",
    "    current_dict['policy_name'] = each_policy[0]\n",
    "    current_dict['sum_difference'] = round(each_policy[1],2)\n",
    "    \n",
    "    policy_dict_list.append(current_dict)\n",
    "\n",
    "print(policy_dict_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'date': '11/28/2020', 'sum_difference': 8.49, 'mean_difference': 0.85, 'standard_deviation_difference': -0.53}]\n"
     ]
    }
   ],
   "source": [
    "#Overall calculation\n",
    "grouped_last = last_date_rows.groupby('Date',as_index=False).agg({'Net Change':[np.sum, np.mean, np.std]})\n",
    "grouped_previous = previous_date_rows.groupby('Date',as_index=False).agg({'Net Change':[np.sum, np.mean, np.std]})\n",
    "\n",
    "#Rename previos frame colums\n",
    "grouped_previous.columns = ['date','prev_sum','prev_mean','prev_std']\n",
    "\n",
    "\n",
    "#Create single comparision frame\n",
    "compare_frame = grouped_last\n",
    "compare_frame.columns = ['date','current_sum','current_mean','current_std']\n",
    "\n",
    "compare_frame['prev_sum'] = grouped_previous['prev_sum']\n",
    "compare_frame['prev_mean'] = grouped_previous['prev_mean']\n",
    "compare_frame['prev_std'] = grouped_previous['prev_std']\n",
    "\n",
    "compare_frame['sum_diff'] = np.where(compare_frame['current_sum'] == compare_frame['prev_sum'], 0 , compare_frame['current_sum'] - compare_frame['prev_sum'])\n",
    "compare_frame['mean_diff'] = np.where(compare_frame['current_mean'] == compare_frame['prev_mean'], 0 , compare_frame['current_mean'] - compare_frame['prev_mean'])\n",
    "compare_frame['std_diff'] = np.where(compare_frame['current_std'] == compare_frame['prev_std'], 0 , compare_frame['current_std'] - compare_frame['prev_std'])\n",
    "\n",
    "compare_frame = compare_frame.drop(['current_sum','current_mean', 'current_std', 'prev_sum','prev_mean', 'prev_std'],axis=1)\n",
    "\n",
    "overall_diff_list = compare_frame.values.tolist()\n",
    "\n",
    "overall_dict_list = []\n",
    "for each_overall in overall_diff_list:\n",
    "    current_dict = {}\n",
    "    current_dict['date'] = each_overall[0]\n",
    "    current_dict['sum_difference'] = round(each_overall[1],2)\n",
    "    current_dict['mean_difference'] = round(each_overall[2],2)\n",
    "    current_dict['standard_deviation_difference'] = round(each_overall[3],2)\n",
    "    \n",
    "    overall_dict_list.append(current_dict)\n",
    "\n",
    "print(overall_dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
