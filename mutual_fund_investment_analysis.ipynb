{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutual Fund Investment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python (Flask) App, majorly for Backend APIs for Individual Mutual Fund Investment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "Over the years, investors have tried and tested various methodologies to keep a track of all investements. The various problems faced for the same are -\n",
    "\n",
    "1. Multi-vendor - The Mutual Funds are invested via multiple vendors, like Groww, Paytm Money, etc., hence no unified interface to track all investments.\n",
    "2. The historic data is not accurately predicted - Over time the historic data loses importance and is overriden to be fitted only in Time Series Graph.\n",
    "3. Periodic Tracking of data - Everyday net change in the invested amount.\n",
    "4. Personalized Prediction - Currently all Mutual Fund Predictions are not personalized, only based on overall NAV changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data collection, Storage and Analysis Blueprint\n",
    "\n",
    "Data from differen apps will be collected in the following way -\n",
    "\n",
    "1. Per day data of return is manually entered in Google Sheet.\n",
    "2. The data from the Google Sheet is fetched in Python, and stored in a MySQL DB.\n",
    "3. Data fetching happens everyday, at 11:00 a.m. (APScheduler)\n",
    "4. Success or failure mails for everyday update is triggered based on the storage of data in the respective database.\n",
    "5. APIs expose the various data, grouped by various factors to be used in the UI.\n",
    "6. Once the stored data crosses a significant volume, this data is splitted into train and test data for future analysis.\n",
    "7. The predicted data is again exposed over APIs, grouped by various factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to Google Sheet\n",
    "\n",
    "Our primary data source is google sheet, where the daily changes for all the mutual funds, are recorded.\n",
    "\n",
    "To connect the Google Sheet, we perform the following -\n",
    "\n",
    "1. Go to https://console.cloud.google.com/ and create a new Project.\n",
    "2. In the created project, enable Google Drive API\n",
    "3. Create credentials to access the Google Drive API.\n",
    "4. Enable the Google Sheets API\n",
    "5. Share the Google Sheet with the dev ID generated in the credential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All imports at one place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/Crypto/Random/Fortuna/FortunaGenerator.py:28: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if sys.version_info[0] is 2 and  sys.version_info[1] is 1:\n",
      "/usr/lib/python3/dist-packages/Crypto/Random/Fortuna/FortunaGenerator.py:28: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if sys.version_info[0] is 2 and  sys.version_info[1] is 1:\n"
     ]
    }
   ],
   "source": [
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import pandas as pd\n",
    "from datetime import datetime,timedelta\n",
    "import smtplib\n",
    "from email.message import EmailMessage\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the scope of the OAuth Authentication\n",
    "scope = [\"https://spreadsheets.google.com/feeds\",'https://www.googleapis.com/auth/spreadsheets',\"https://www.googleapis.com/auth/drive.file\",\"https://www.googleapis.com/auth/drive\"]\n",
    "         \n",
    "#Getting the credentials\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name(\"./flask_app/src/secret_config/google_credentials.json\", scope)\n",
    "#Connecting to the Google Spreadsheet Client\n",
    "client = gspread.authorize(creds)\n",
    "\n",
    "#Getting the spreadsheet\n",
    "sheet = client.open(\"Daily_MF_Returns\").sheet1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting all the data from the sheet\n",
    "\n",
    "Explore the sheet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_data = sheet.get_all_records()\n",
    "\n",
    "#Creating the dataframe\n",
    "data = pd.DataFrame(list_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130, 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rows and Column Count for the data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Policy Name', 'App', 'Investment', 'Return', 'Net Change'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Column Names of the data\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 130 entries, 0 to 129\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Date         130 non-null    object\n",
      " 1   Policy Name  130 non-null    object\n",
      " 2   App          130 non-null    object\n",
      " 3   Investment   130 non-null    int64 \n",
      " 4   Return       130 non-null    object\n",
      " 5   Net Change   130 non-null    object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 6.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#explore the data\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-650b1a9ff6ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data.tail(5).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing Empty Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace([''],'Unknown',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Formatted Date column to the dataframe\n",
    "\n",
    "The new column contains date in format DD-MMM-YYYY to avoid ambiguity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coverting all the values in proper Datetime format\n",
    "\n",
    "def validate(date_text):\n",
    "    try:\n",
    "        return datetime.strptime(date_text, '%m/%d/%Y').strftime(\"%d-%b-%Y\")\n",
    "    except ValueError:\n",
    "        print(date_text)\n",
    "        return date_text\n",
    "    \n",
    "data['date_formatted'] = data['Date'].apply(validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update the Excel for next week (repetitive)\n",
    "\n",
    "### Get the last date, and all the records for last date\n",
    "We'll update the data for next week (Tuesday - Saturday), every previous Saturday\n",
    "To do this the following has to be calculated -\n",
    "\n",
    "1. Index of the current pointer in the excel\n",
    "2. The last date\n",
    "3. All the records for the last date (fetch Date, Policy Name, App and Investment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['11/28/2020', 'IDFC Low Duration', 'Paytm Money', 1600], ['11/28/2020', 'BOI AXA', 'Paytm Money', 200], ['11/28/2020', 'SBI Short Term', 'Paytm Money', 1000], ['11/28/2020', 'Edelweiss Banking and PSU', 'Paytm Money', 500], ['11/28/2020', 'HDFC Gold Direct', 'Paytm Money', 500], ['11/28/2020', 'Nippon India Liquid Fund', 'Paytm Money', 800], ['11/28/2020', 'ICICI Prudential Regular Gold', 'Groww', 500], ['11/28/2020', 'Axis Midcap Direct', 'Groww', 500], ['11/28/2020', 'Axis Bluechip', 'Groww', 500], ['11/28/2020', 'SBI Magnum', 'Groww', 500]]\n"
     ]
    }
   ],
   "source": [
    "current_pointer = len(list_data)\n",
    "\n",
    "#Getting the last date\n",
    "last_date = data.values[current_pointer-1][0]\n",
    "\n",
    "#Getting all the rows corresponding to the last date\n",
    "data_filtered = data.loc[data['Date'] == last_date]\n",
    "\n",
    "data_filtered = data_filtered.drop(['Return','Net Change', 'date_formatted'],axis=1)\n",
    "\n",
    "# List of dictionaries\n",
    "list_to_insert = data_filtered.values.tolist()\n",
    "\n",
    "print(list_to_insert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the final list of data to be inserted\n",
    "\n",
    "1. Start from 2 days from the date\n",
    "2. Create for 5 days\n",
    "3. Total # rows = Current # rows * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_insert_list = []\n",
    "\n",
    "for i in range(0,5):\n",
    "    for each_row in list_to_insert:        \n",
    "        final_insert_list.append(each_row)\n",
    "\n",
    "# Yield successive n-sized \n",
    "# chunks from l. \n",
    "def divide_chunks(l, n):       \n",
    "    # looping till length l \n",
    "    for i in range(0, len(l), n):  \n",
    "        yield l[i:i + n]\n",
    "        \n",
    "days_chunk = list(divide_chunks(final_insert_list, len(list_to_insert)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Records and Send Mail\n",
    "\n",
    "1. Update the next weeks data in the sheet\n",
    "2. Send success and failure mails accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Row - 82\n",
      "Updated Row - 83\n",
      "Updated Row - 84\n",
      "Updated Row - 85\n",
      "Updated Row - 86\n",
      "Updated Row - 87\n",
      "Updated Row - 88\n",
      "Updated Row - 89\n",
      "Updated Row - 90\n",
      "Updated Row - 91\n",
      "Updated Row - 92\n",
      "Updated Row - 93\n",
      "Updated Row - 94\n",
      "Updated Row - 95\n",
      "Updated Row - 96\n",
      "Updated Row - 97\n",
      "Updated Row - 98\n",
      "Updated Row - 99\n",
      "Updated Row - 100\n",
      "Updated Row - 101\n",
      "Updated Row - 102\n",
      "Updated Row - 103\n",
      "Updated Row - 104\n",
      "Updated Row - 105\n",
      "Updated Row - 106\n",
      "Updated Row - 107\n",
      "Updated Row - 108\n",
      "Updated Row - 109\n",
      "Updated Row - 110\n",
      "Updated Row - 111\n",
      "Updated Row - 112\n",
      "Updated Row - 113\n",
      "Updated Row - 114\n",
      "Updated Row - 115\n",
      "Updated Row - 116\n",
      "Updated Row - 117\n",
      "Updated Row - 118\n",
      "Updated Row - 119\n",
      "Updated Row - 120\n",
      "Updated Row - 121\n",
      "Updated Row - 122\n",
      "Updated Row - 123\n",
      "Updated Row - 124\n",
      "Updated Row - 125\n",
      "Updated Row - 126\n",
      "Updated Row - 127\n",
      "Updated Row - 128\n",
      "Updated Row - 129\n",
      "Updated Row - 130\n",
      "Updated Row - 131\n",
      "Email sent successfully\n"
     ]
    }
   ],
   "source": [
    "def email_alert(subject, body, to):\n",
    "    msg=EmailMessage()\n",
    "    msg.set_content(body)\n",
    "    msg['subject']=subject\n",
    "    msg['to'] = to\n",
    "    \n",
    "    gmail_credentials_file = open(\"./flask_app/src/secret_config/gmail_credentials.json\")\n",
    "    gmail_credentials = json.load(gmail_credentials_file)\n",
    "    \n",
    "    sender = gmail_credentials['email']\n",
    "    password = gmail_credentials['password']    \n",
    "    \n",
    "    msg['from'] = sender\n",
    "    \n",
    "    server = smtplib.SMTP(\"smtp.gmail.com\", 587)\n",
    "    server.starttls()\n",
    "    server.login(sender,password)\n",
    "    \n",
    "    server.send_message(msg)\n",
    "    server.quit()\n",
    "    print(\"Email sent successfully\");\n",
    "\n",
    "success_insert = True\n",
    "total_rows = data.shape[0] + 2 # 1st Row is heading\n",
    "\n",
    "days_delta = 3\n",
    "\n",
    "for each_chunk in days_chunk:\n",
    "    if(success_insert):\n",
    "        date_to_add = (datetime.strptime(last_date, '%m/%d/%Y') + timedelta(days=days_delta)).strftime('%m/%d/%Y')\n",
    "        for value in each_chunk:\n",
    "            value[0] = date_to_add\n",
    "            try:\n",
    "                sheet.insert_row(value, total_rows, 'RAW')\n",
    "                print(\"Updated Row - \" + str(total_rows))\n",
    "                total_rows += 1                \n",
    "            except:\n",
    "                print(\"Error in Row - \" + str(total_rows))\n",
    "                success_insert = False\n",
    "                break\n",
    "        days_delta +=1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "start_date = (datetime.strptime(last_date, '%m/%d/%Y') + timedelta(days=3)).strftime('%d-/%b-%Y')\n",
    "\n",
    "if(success_insert):\n",
    "    body = '''\n",
    "    Hi Apratim,\n",
    "    \n",
    "    The weekly scheduled insert of data is successful. Data is inserted for the next 5 days, starting from Tuesday - {var}.\n",
    "    Please update the returns accordingly.\n",
    "    \n",
    "    Best Regards,\n",
    "    Dev Team\n",
    "    Mutual Fund Analysis App'''.format(var=start_date)\n",
    "else:\n",
    "    body = '''\n",
    "    Hi Apratim,\n",
    "    \n",
    "    There was some issue in updating your data. Rest assured our team is working on it.\n",
    "    Meanwhile please update the data and returns manually, starting from - {var}.\n",
    "    Sorry for the incovenience caused.\n",
    "    \n",
    "    Best Regards,\n",
    "    Dev Team\n",
    "    Mutual Fund Analysis App'''.format(var=start_date)\n",
    "    \n",
    "subject = \"Mutual Funds - Weekly Insertion of Base Data\"\n",
    "to = \"apratimnath7@gmail.com\";\n",
    "\n",
    "email_alert(subject, body, to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculations (Transferred via API)\n",
    "\n",
    "API 1 - Get the daily change based on the following parameters -\n",
    "1. Overall\n",
    "2. App Based\n",
    "3. Fund Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-65-30f27d17b758>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  last_date_rows['Investment'] = pd.to_numeric(last_date_rows['Investment'])\n",
      "<ipython-input-65-30f27d17b758>:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  last_date_rows['Return'] = pd.to_numeric(last_date_rows['Return'])\n",
      "<ipython-input-65-30f27d17b758>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  last_date_rows['Net Change'] = pd.to_numeric(last_date_rows['Net Change'])\n"
     ]
    }
   ],
   "source": [
    "#Subset of data containing returns\n",
    "valid_data_with_returns = data.loc[data['Return'] != 'Unknown']\n",
    "\n",
    "length_of_valid_returns = valid_data_with_returns.shape[0]\n",
    "\n",
    "#Getting the last date\n",
    "last_date = valid_data_with_returns.values[length_of_valid_returns-1][0]\n",
    "\n",
    "#Get the last date and the date before that data\n",
    "last_date_rows = valid_data_with_returns.loc[valid_data_with_returns['Date'] == last_date]\n",
    "previous_date_rows = valid_data_with_returns.loc[valid_data_with_returns['Date'] != last_date].tail(last_date_rows.shape[0])\n",
    "\n",
    "# last_date_rows_list = last_date_rows.values.tolist()\n",
    "# previous_date_rows_list = previous_date_rows.values.tolist()\n",
    "\n",
    "#Convert to numeric\n",
    "last_date_rows['Investment'] = pd.to_numeric(last_date_rows['Investment'])\n",
    "last_date_rows['Return'] = pd.to_numeric(last_date_rows['Return'])\n",
    "last_date_rows['Net Change'] = pd.to_numeric(last_date_rows['Net Change'])\n",
    "\n",
    "previous_date_rows['Investment'] = pd.to_numeric(previous_date_rows['Investment'])\n",
    "previous_date_rows['Return'] = pd.to_numeric(previous_date_rows['Return'])\n",
    "previous_date_rows['Net Change'] = pd.to_numeric(previous_date_rows['Net Change'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### App Wise Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'app_name': 'Groww', 'sum_difference': 8.0, 'mean_difference': 2.0, 'standard_deviation_difference': 4.7}, {'app_name': 'Paytm Money', 'sum_difference': 0.49, 'mean_difference': 0.08, 'standard_deviation_difference': -0.39}]\n"
     ]
    }
   ],
   "source": [
    "#App-wise calculation\n",
    "grouped_last = last_date_rows.groupby('App',as_index=False).agg({'Net Change':[np.sum, np.mean, np.std]})\n",
    "grouped_previous = previous_date_rows.groupby('App',as_index=False).agg({'Net Change':[np.sum, np.mean, np.std]})\n",
    "\n",
    "#Rename previos frame colums\n",
    "grouped_previous.columns = ['app','prev_sum','prev_mean','prev_std']\n",
    "\n",
    "\n",
    "#Create single comparision frame\n",
    "compare_frame = grouped_last\n",
    "compare_frame.columns = ['app','current_sum','current_mean','current_std']\n",
    "\n",
    "compare_frame['prev_sum'] = grouped_previous['prev_sum']\n",
    "compare_frame['prev_mean'] = grouped_previous['prev_mean']\n",
    "compare_frame['prev_std'] = grouped_previous['prev_std']\n",
    "\n",
    "compare_frame['sum_diff'] = np.where(compare_frame['current_sum'] == compare_frame['prev_sum'], 0 , compare_frame['current_sum'] - compare_frame['prev_sum'])\n",
    "compare_frame['mean_diff'] = np.where(compare_frame['current_mean'] == compare_frame['prev_mean'], 0 , compare_frame['current_mean'] - compare_frame['prev_mean'])\n",
    "compare_frame['std_diff'] = np.where(compare_frame['current_std'] == compare_frame['prev_std'], 0 , compare_frame['current_std'] - compare_frame['prev_std'])\n",
    "\n",
    "compare_frame = compare_frame.drop(['current_sum','current_mean', 'current_std', 'prev_sum','prev_mean', 'prev_std'],axis=1)\n",
    "\n",
    "app_diff_list = compare_frame.values.tolist()\n",
    "\n",
    "app_dict_list = []\n",
    "for each_app in app_diff_list:\n",
    "    current_dict = {}\n",
    "    current_dict['app_name'] = each_app[0]\n",
    "    current_dict['sum_difference'] = round(each_app[1],2)\n",
    "    current_dict['mean_difference'] = round(each_app[2],2)\n",
    "    current_dict['standard_deviation_difference'] = round(each_app[3],2)\n",
    "    \n",
    "    app_dict_list.append(current_dict)\n",
    "\n",
    "print(app_dict_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fund Based Calculation\n",
    "\n",
    "Since the values are independent, ideally group by has no effect.\n",
    "\n",
    "However, we keep on using the costlier grouping to keep things inline with the previous implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'policy_name': 'Axis Bluechip', 'sum_difference': -1.0}, {'policy_name': 'Axis Midcap Direct', 'sum_difference': 10.0}, {'policy_name': 'BOI AXA', 'sum_difference': 2.82}, {'policy_name': 'Edelweiss Banking and PSU', 'sum_difference': 0.1}, {'policy_name': 'HDFC Gold Direct', 'sum_difference': -2.11}, {'policy_name': 'ICICI Prudential Regular Gold', 'sum_difference': -1.0}, {'policy_name': 'IDFC Low Duration', 'sum_difference': 0.09}, {'policy_name': 'Nippon India Liquid Fund', 'sum_difference': 0.06}, {'policy_name': 'SBI Magnum', 'sum_difference': 0.0}, {'policy_name': 'SBI Short Term', 'sum_difference': -0.47}]\n"
     ]
    }
   ],
   "source": [
    "#Fund-wise calculation\n",
    "grouped_last = last_date_rows.groupby('Policy Name',as_index=False).agg({'Net Change':[np.sum]})\n",
    "grouped_previous = previous_date_rows.groupby('Policy Name',as_index=False).agg({'Net Change':[np.sum]})\n",
    "\n",
    "#Rename previos frame colums\n",
    "grouped_previous.columns = ['policy_name','prev_sum']\n",
    "\n",
    "\n",
    "#Create single comparision frame\n",
    "compare_frame = grouped_last\n",
    "compare_frame.columns = ['policy_name','current_sum']\n",
    "\n",
    "compare_frame['prev_sum'] = grouped_previous['prev_sum']\n",
    "\n",
    "compare_frame['sum_diff'] = np.where(compare_frame['current_sum'] == compare_frame['prev_sum'], 0 , compare_frame['current_sum'] - compare_frame['prev_sum'])\n",
    "\n",
    "compare_frame = compare_frame.drop(['current_sum', 'prev_sum'],axis=1)\n",
    "\n",
    "policy_diff_list = compare_frame.values.tolist()\n",
    "\n",
    "policy_dict_list = []\n",
    "for each_policy in policy_diff_list:\n",
    "    current_dict = {}\n",
    "    current_dict['policy_name'] = each_policy[0]\n",
    "    current_dict['sum_difference'] = round(each_policy[1],2)\n",
    "    \n",
    "    policy_dict_list.append(current_dict)\n",
    "\n",
    "print(policy_dict_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'date': '11/28/2020', 'sum_difference': 8.49, 'mean_difference': 0.85, 'standard_deviation_difference': -0.53}]\n"
     ]
    }
   ],
   "source": [
    "#Overall calculation\n",
    "grouped_last = last_date_rows.groupby('Date',as_index=False).agg({'Net Change':[np.sum, np.mean, np.std]})\n",
    "grouped_previous = previous_date_rows.groupby('Date',as_index=False).agg({'Net Change':[np.sum, np.mean, np.std]})\n",
    "\n",
    "#Rename previos frame colums\n",
    "grouped_previous.columns = ['date','prev_sum','prev_mean','prev_std']\n",
    "\n",
    "\n",
    "#Create single comparision frame\n",
    "compare_frame = grouped_last\n",
    "compare_frame.columns = ['date','current_sum','current_mean','current_std']\n",
    "\n",
    "compare_frame['prev_sum'] = grouped_previous['prev_sum']\n",
    "compare_frame['prev_mean'] = grouped_previous['prev_mean']\n",
    "compare_frame['prev_std'] = grouped_previous['prev_std']\n",
    "\n",
    "compare_frame['sum_diff'] = np.where(compare_frame['current_sum'] == compare_frame['prev_sum'], 0 , compare_frame['current_sum'] - compare_frame['prev_sum'])\n",
    "compare_frame['mean_diff'] = np.where(compare_frame['current_mean'] == compare_frame['prev_mean'], 0 , compare_frame['current_mean'] - compare_frame['prev_mean'])\n",
    "compare_frame['std_diff'] = np.where(compare_frame['current_std'] == compare_frame['prev_std'], 0 , compare_frame['current_std'] - compare_frame['prev_std'])\n",
    "\n",
    "compare_frame = compare_frame.drop(['current_sum','current_mean', 'current_std', 'prev_sum','prev_mean', 'prev_std'],axis=1)\n",
    "\n",
    "overall_diff_list = compare_frame.values.tolist()\n",
    "\n",
    "overall_dict_list = []\n",
    "for each_overall in overall_diff_list:\n",
    "    current_dict = {}\n",
    "    current_dict['date'] = each_overall[0]\n",
    "    current_dict['sum_difference'] = round(each_overall[1],2)\n",
    "    current_dict['mean_difference'] = round(each_overall[2],2)\n",
    "    current_dict['standard_deviation_difference'] = round(each_overall[3],2)\n",
    "    \n",
    "    overall_dict_list.append(current_dict)\n",
    "\n",
    "print(overall_dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
